{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2716a096",
   "metadata": {},
   "source": [
    "# This notebook will not run. It functions as a location to assemble functions for the final report. These may not be the final iterations of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b269cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(conflict):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    low=conflict[conflict['time_to_conflict']<7000]\n",
    "    sns.histplot(x='time_to_conflict', data=low)\n",
    "    plt.title('All Conflict\\'s Time to Conflict')\n",
    "    plt.xlabel('Time to Conflict')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae847970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_stat(train):\n",
    "    asia=train[train['region']=='3']\n",
    "    notasia=train[train['region']!='3']\n",
    "    t, p=stats.ttest_ind(asia['time_to_conflict'], notasia['time_to_conflict'], alternative='greater')\n",
    "    alpha = 0.5\n",
    "    if p < alpha:\n",
    "        print('After an independent t-test was conducted:')\n",
    "        print(f'The p-value ({round(p,3)}) is lower than the alpha ({alpha}).')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_plots(train):\n",
    "    '''\n",
    "    This function plots the necessary plots to visualize explore question 2\n",
    "    '''\n",
    "    ame=train[(train['region']=='2') | (train['region']=='4')]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(221)\n",
    "    sns.histplot(x='time_to_conflict', data=ame)\n",
    "    plt.title('Time to Conflict (Africa and Middle East)')\n",
    "    plt.xlabel('Time to Conflict (days)')\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    sns.histplot(x='time_to_conflict', data=train)\n",
    "    plt.title('All Regions')\n",
    "    plt.xlabel('Time to Conflict (days)')\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.subplot(223)\n",
    "    plt.title('Africa and Middle East vs All Regions (Time to Conflict)')\n",
    "    sns.histplot(x='time_to_conflict', data=ame, alpha=.5, color='green', label= 'Africa and Middle East')\n",
    "    sns.histplot(x='time_to_conflict', data=train, alpha=.25, label='All Regions')\n",
    "    plt.xlabel('Time to Conflict')\n",
    "    plt.axvline(x=(ame['time_to_conflict'].mean()), color='red', label='Africa and Middle East Mean')\n",
    "    plt.axvline(x=(train['time_to_conflict'].mean()), color='yellow', label='All Regions Mean')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                            bottom=-0.1,\n",
    "                            right=0.9,\n",
    "                            top=0.9,\n",
    "                            wspace=0.4,\n",
    "                            hspace=0.4)\n",
    "    plt.show()\n",
    "    \n",
    "    asiam=round(ame['time_to_conflict'].mean(),2)\n",
    "    notasiam=round(train['time_to_conflict'].mean(),2)\n",
    "    print(f'The mean time to conflict for Africa and the Middle East is {asiam}.')\n",
    "    print(f'The mean time to conflict for all regions is {notasiam}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef938ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_stat(train):\n",
    "    ame=train[(train['region']=='2') | (train['region']=='4')]\n",
    "    trainmean=train['time_to_conflict'].mean()\n",
    "    t, p = stats.ttest_1samp(ame['time_to_conflict'], trainmean, alternative='less')\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('After a one sample t-test was conducted:')\n",
    "        print(f'The p-value ({round(p,3)}) is lower than the alpha ({alpha}).')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d28ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_plots(train):\n",
    "    '''\n",
    "    This function plots the necessary plots to visualize explore question 3\n",
    "    '''\n",
    "    intra=train[(train['type_of_conflict']==3)&(train['incompatibility']==2)]\n",
    "    inter=train[(train['type_of_conflict']==2)&(train['incompatibility']==1)]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(221)\n",
    "    sns.histplot(x='time_to_conflict', data=intra)\n",
    "    plt.title('Time to Conflict (Intrastate/Government)')\n",
    "    plt.xlabel('Time to Conflict (days)')\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    sns.histplot(x='time_to_conflict', data=inter)\n",
    "    plt.title('Time to Conflict (Interstate/Territory)')\n",
    "    plt.xlabel('Time to Conflict (days)')\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.subplot(223)\n",
    "    plt.title('Intrastate/Government vs Interstate/Territory Time to Conflict')\n",
    "    sns.histplot(x='time_to_conflict', data=intra, alpha=.2, color='green', label= 'Intrastate/Government')\n",
    "    sns.histplot(x='time_to_conflict', data=inter, alpha=1, label='Interstate/Territory')\n",
    "    plt.xlabel('Time to Conflict')\n",
    "    plt.axvline(x=(intra['time_to_conflict'].mean()), color='red', label='Intrastate/Government')\n",
    "    plt.axvline(x=(inter['time_to_conflict'].mean()), color='yellow', label='Interstate/Territory')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                            bottom=-0.1,\n",
    "                            right=0.9,\n",
    "                            top=0.9,\n",
    "                            wspace=0.4,\n",
    "                            hspace=0.4)\n",
    "    plt.show()\n",
    "    \n",
    "    asiam=round(intra['time_to_conflict'].mean(),2)\n",
    "    notasiam=round(inter['time_to_conflict'].mean(),2)\n",
    "    print(f'The mean time to conflict for countries with intrastate conflict over government is {asiam}.')\n",
    "    print(f'The mean time to conflict for countries with an interstate conflict over territory is {notasiam}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_stat(train):\n",
    "    '''\n",
    "    this function performs the necessary stats test for question 3\n",
    "    '''\n",
    "    intra=train[(train['type_of_conflict']==3)&(train['incompatibility']==2)]\n",
    "    inter=train[(train['type_of_conflict']==2)&(train['incompatibility']==1)]\n",
    "    t, p=stats.mannwhitneyu(intra['time_to_conflict'], inter['time_to_conflict'], alternative='greater')\n",
    "    alpha = 0.05\n",
    "    if p < alpha:\n",
    "        print('After a mannwhitneyu stats test was conducted:')\n",
    "        print(f'The p-value ({round(p,3)}) is lower than the alpha ({alpha}).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q4_stat(train):\n",
    "    '''\n",
    "    this function performs the necessary stats test for question 4\n",
    "    '''\n",
    "    ii=train[train['type_of_conflict']==4]\n",
    "    ii2=[]\n",
    "    for x in ii['time_to_conflict']:\n",
    "        ii2.append(x-359)\n",
    "    t,p=stats.wilcoxon(ii2, alternative='less')\n",
    "    alpha = 0.05\n",
    "    if p < alpha:\n",
    "        print('After a wilcoxon stats test was conducted:')\n",
    "        print(f'The p-value ({round(p,3)}) is lower than the alpha ({alpha}).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1aba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prep():\n",
    "    '''\n",
    "    this function prepares the data for modeling\n",
    "    '''\n",
    "    conflict=explore_conflict()\n",
    "    for i, n in enumerate(conflict['location']):\n",
    "        if n=='India':\n",
    "            conflict.at[i, 'location'] = 0\n",
    "        elif n=='Russia (Soviet Union)':\n",
    "            conflict.at[i, 'location'] = 1\n",
    "        elif n=='Myanmar (Burma)':\n",
    "            conflict.at[i, 'location'] = 2\n",
    "        elif n=='Ethiopia':\n",
    "            conflict.at[i, 'location'] = 3\n",
    "        elif n=='Indonesia':\n",
    "            conflict.at[i, 'location'] = 4\n",
    "        elif n=='Nigeria':\n",
    "            conflict.at[i, 'location'] = 5\n",
    "        elif n=='DR Congo (Zaire)':\n",
    "            conflict.at[i, 'location'] = 6\n",
    "        elif n=='Iran':\n",
    "            conflict.at[i, 'location'] = 7\n",
    "        elif n=='Ukraine':\n",
    "            conflict.at[i, 'location'] = 8\n",
    "        elif n=='Pakistan':\n",
    "            conflict.at[i, 'location'] = 9\n",
    "        else:\n",
    "            conflict.at[i, 'location'] = 10\n",
    "    for i, n in enumerate(conflict['side_a']):\n",
    "        if n=='Government of India':\n",
    "            conflict.at[i, 'side_a'] = 0\n",
    "        elif n=='Government of France':\n",
    "            conflict.at[i, 'side_a'] = 1\n",
    "        elif n=='Government of Russia (Soviet Union)':\n",
    "            conflict.at[i, 'side_a'] = 2\n",
    "        elif n=='Government of Myanmar (Burma)':\n",
    "            conflict.at[i, 'side_a'] = 3\n",
    "        elif n=='Government of Ethiopia':\n",
    "            conflict.at[i, 'side_a'] = 4\n",
    "        elif n=='Government of China':\n",
    "            conflict.at[i, 'side_a'] = 5\n",
    "        elif n=='Government of Iran':\n",
    "            conflict.at[i, 'side_a'] = 6\n",
    "        elif n=='Government of United Kingdom':\n",
    "            conflict.at[i, 'side_a'] = 7\n",
    "        elif n=='Government of Indonesia':\n",
    "            conflict.at[i, 'side_a'] = 8\n",
    "        elif n=='Government of DR Congo (Zaire)':\n",
    "            conflict.at[i, 'side_a'] = 9\n",
    "        else:\n",
    "            conflict.at[i, 'side_a'] = 10 \n",
    "    for i, n in enumerate(conflict['side_b']):\n",
    "        if n=='IS':\n",
    "            conflict.at[i, 'side_b'] = 0\n",
    "        elif n=='Government of Thailand':\n",
    "            conflict.at[i, 'side_b'] = 1\n",
    "        elif n=='Government of United Kingdom':\n",
    "            conflict.at[i, 'side_b'] = 2\n",
    "        elif n=='Government of Russia (Soviet Union)':\n",
    "            conflict.at[i, 'side_b'] = 3\n",
    "        elif n=='Government of Israel':\n",
    "            conflict.at[i, 'side_b'] = 4\n",
    "        elif n=='Government of Vietnam (North Vietnam)':\n",
    "            conflict.at[i, 'side_b'] = 5\n",
    "        elif n=='Government of Iraq':\n",
    "            conflict.at[i, 'side_b'] = 6\n",
    "        elif n=='PLA':\n",
    "            conflict.at[i, 'side_b'] = 7\n",
    "        elif n=='UCK':\n",
    "            conflict.at[i, 'side_b'] = 8\n",
    "        elif n=='POLISARIO':\n",
    "            conflict.at[i, 'side_b'] = 9\n",
    "        elif n=='National Liberation Army':\n",
    "            conflict.at[i, 'side_b'] = 10\n",
    "        elif n=='Government of India':\n",
    "            conflict.at[i, 'side_b'] = 11\n",
    "        elif n=='CPM':\n",
    "            conflict.at[i, 'side_b'] = 12\n",
    "        elif n=='Government of Nigeria':\n",
    "            conflict.at[i, 'side_b'] = 13\n",
    "        elif n=='Government of United States of America':\n",
    "            conflict.at[i, 'side_b'] = 14\n",
    "        elif n=='NLA':\n",
    "            conflict.at[i, 'side_b'] = 15\n",
    "        elif n=='CPI':\n",
    "            conflict.at[i, 'side_b'] = 16\n",
    "        elif n=='UPC':\n",
    "            conflict.at[i, 'side_b'] = 17\n",
    "        elif n=='Military faction (navy)':\n",
    "            conflict.at[i, 'side_b'] = 18\n",
    "        elif n=='AQIM':\n",
    "            conflict.at[i, 'side_b'] = 19\n",
    "        else:\n",
    "            conflict.at[i, 'side_b'] = 20\n",
    "    for i, n in enumerate(conflict.start_date.astype('str').str.startswith('19')):\n",
    "        if n==True:\n",
    "            conflict.at[i, 'start_date'] = 0\n",
    "        else:\n",
    "            conflict.at[i, 'start_date'] = 1\n",
    "    for i, n in enumerate(conflict['time_to_conflict']):\n",
    "        if n<=30:\n",
    "            conflict.at[i, 'time_to_conflict'] = 1\n",
    "        elif 30<n<=365:\n",
    "            conflict.at[i, 'time_to_conflict'] = 2\n",
    "        elif n>365:\n",
    "            conflict.at[i, 'time_to_conflict'] = 3\n",
    "    conflict=pd.get_dummies(conflict, columns=['location','side_a', 'side_a_2nd', 'side_b',\n",
    "                                           'side_b_2nd', 'type_of_conflict',\n",
    "                                           'region', 'incompatibility', 'start_date'])\n",
    "    conflict=conflict.drop(columns=['territory_name', 'start_date2'])\n",
    "    conflict=conflict.astype('int')\n",
    "    return conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(train):\n",
    "    '''\n",
    "    this function gives the baseline'''\n",
    "    train['baseline']=1\n",
    "    x_train= train.drop(columns=['time_to_conflict'])\n",
    "    y_train= train['time_to_conflict']\n",
    "    base=accuracy_score(y_train, train['baseline'])\n",
    "    return print(f'The baseline to try and beat for modeling is {round(base,3)}.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(train, val):\n",
    "    '''\n",
    "    this function prints results for models\n",
    "    '''\n",
    "    x_train= train.drop(columns=['time_to_conflict'])\n",
    "    y_train= train['time_to_conflict']\n",
    "\n",
    "    x_val= val.drop(columns=['time_to_conflict'])\n",
    "    y_val= val['time_to_conflict']\n",
    "    \n",
    "    results=[]\n",
    "    logit = LogisticRegression(C=.5, random_state=8675309, intercept_scaling=1, solver='lbfgs')\n",
    "    logit.fit(x_train, y_train)\n",
    "    in_sample=logit.score(x_train,y_train)\n",
    "    out_of_sample=logit.score(x_val, y_val)\n",
    "    output={\n",
    "        'model': 'LogisticRegression (lbfgs)',\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample\n",
    "    }\n",
    "    results.append(output)\n",
    "    \n",
    "    logit = LogisticRegression(C=1, random_state=8675309, solver='liblinear')\n",
    "    logit.fit(x_train, y_train)\n",
    "    in_sample=logit.score(x_train,y_train)\n",
    "    out_of_sample=logit.score(x_val, y_val)\n",
    "    output={\n",
    "        'model': 'LogisticRegression (liblinear)',\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample\n",
    "    }\n",
    "    results.append(output)\n",
    "    \n",
    "    knn= KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "    knn.fit(x_train,y_train)\n",
    "    in_sample= knn.score(x_train, y_train)\n",
    "    out_of_sample= knn.score(x_val, y_val)\n",
    "    output={\n",
    "        'model': 'KNeighborsClassifier',\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample\n",
    "    }\n",
    "    results.append(output)\n",
    "    \n",
    "    dtc=DecisionTreeClassifier(max_depth=2, min_samples_leaf=1, random_state=8675309)\n",
    "    dtc.fit(x_train, y_train)\n",
    "    in_sample= dtc.score(x_train, y_train)\n",
    "    out_of_sample= dtc.score(x_val, y_val)\n",
    "    output={\n",
    "        'model': 'DecisionTreeClassifier',\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample\n",
    "    }\n",
    "    results.append(output)\n",
    "    \n",
    "    rm= RandomForestClassifier(max_depth= 2, min_samples_leaf= 1, random_state=8675309)\n",
    "    rm.fit(x_train, y_train)\n",
    "    in_sample= rm.score(x_train, y_train)\n",
    "    out_of_sample= rm.score(x_val, y_val)\n",
    "    output={\n",
    "        'model': 'RandomForestClassifier',\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample\n",
    "    }\n",
    "    results.append(output)\n",
    "    \n",
    "    results=pd.DataFrame(data=results)\n",
    "    results['difference']=results['train_accuracy']-results['validate_accuracy'] \n",
    "    results.head().sort_values(by='difference', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(train,val,test):\n",
    "    '''\n",
    "    this function shows the results of the test data\n",
    "    '''\n",
    "    x_train= train.drop(columns=['time_to_conflict'])\n",
    "    y_train= train['time_to_conflict']\n",
    "\n",
    "    x_val= val.drop(columns=['time_to_conflict'])\n",
    "    y_val= val['time_to_conflict']\n",
    "\n",
    "    x_test= test.drop(columns=['time_to_conflict'])\n",
    "    y_test= test['time_to_conflict']\n",
    "    \n",
    "    results=[]\n",
    "    logit = LogisticRegression(C=.5, random_state=8675309, intercept_scaling=1, solver='lbfgs')\n",
    "    logit.fit(x_train, y_train)\n",
    "    trainacc = logit.score(x_train,y_train)\n",
    "    valacc = logit.score(x_val, y_val)\n",
    "    testacc=logit.score(x_test, y_test)\n",
    "    output={\n",
    "        'train_accuracy': trainacc,\n",
    "        'validate_accuracy': valacc,\n",
    "        'test_accuracy': testacc\n",
    "    }\n",
    "    results.append(output)\n",
    "\n",
    "    logit = LogisticRegression(C=1, random_state=8675309, solver='liblinear')\n",
    "    logit.fit(x_train, y_train)\n",
    "    trainacc2 = logit.score(x_train,y_train)\n",
    "    valacc2 = logit.score(x_val, y_val)\n",
    "    \n",
    "    train['baseline']=1\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    X = ['Logistic Regression (lbfgs)','Logistic Regression (liblinear)']\n",
    "    baseline=accuracy_score(y_train, train['baseline'])\n",
    "\n",
    "    X_axis = np.arange(len(X))\n",
    "\n",
    "    plt.bar(X_axis[0] - 0.2, trainacc, 0.2, label = 'Train Accuracy', color=['blue'], ec='black')\n",
    "    plt.bar(X_axis[0] + 0, valacc, 0.2, label = 'Validate Accuracy', color=['green'], ec='black')\n",
    "    plt.bar(X_axis[0] + 0.2, testacc, 0.2, label = 'Test Accuracy', color=['rebeccapurple'], ec='black')\n",
    "\n",
    "\n",
    "    plt.bar(X_axis[1] - 0.1, trainacc2, 0.2, color=['blue'], ec='black')\n",
    "    plt.bar(X_axis[1] + 0.1, valacc2, 0.2, color=['green'], ec='black')\n",
    "\n",
    "\n",
    "    plt.axhline(y = baseline, color = 'r', linestyle = '-', label='Baseline Accuracy')\n",
    "\n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy of Models vs Baseline\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    results=pd.DataFrame(data=results)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
